# PCGNet-PP

**PCGNet++: Improved Point Cloud Generation Network for Occluded Objects using Monocular Images and Radar**

This repository contains the official implementation of **PCGNet++**, a multi-modal point cloud generation network designed for enhancing perception of occluded objects in autonomous driving scenarios. The framework fuses monocular image features and millimeter-wave radar to produce high-quality, semantically meaningful point clouds.

---

## ðŸ”§ Project Structure

```
PCGNet-PP/
â”œâ”€â”€ main.py # Entry point for training/evaluation
â”œâ”€â”€ setup.py # Python package setup
â”œâ”€â”€ task3_env.yml # Conda environment dependencies
â”œâ”€â”€ src/ # Core model implementation
â”œâ”€â”€ test_ops/ # Utility modules and testing operations
â”œâ”€â”€ VoxelPooling.egg-info/ # Metadata from setup
â””â”€â”€ README.md # Project description and instructions
```


---

## ðŸ“¦ Environment Setup

We recommend using **conda** to manage the dependencies.

```bash
# Create and activate conda environment
conda env create -f task3_env.yml
```
Ensure CUDA and PyTorch are correctly installed for GPU acceleration.

---

## ðŸ“Š Datasets & Evaluation

We evaluate **PCGNet++** on our self-constructed dataset, **FlexRadar**, a **multi-modal dataset specifically designed for point cloud quality evaluation**. 


> ðŸ”’ **Note:** The FlexRadar dataset will be made publicly available upon acceptance of our dataset paper.  
> ðŸ“‚ **Repository:** For more details, please visit the https://github.com/Aiuan/ourDataset_v2_postprocess, https://github.com/Aiuan/sensors_calibration_v2.1.
